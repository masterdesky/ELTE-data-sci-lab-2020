{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigable network\n",
    " In this project I will try to reproduce the research about finding a route or path between twitter users, useing decentralized algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import powerlaw as pw\n",
    "import networkx as nx\n",
    "import collections as col\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = './data/'\n",
    "path_pic = './output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just some matplotlib and seaborn parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axistitlesize = 20\n",
    "axisticksize = 17\n",
    "axislabelsize = 26\n",
    "axislegendsize = 20\n",
    "axistextsize = 20\n",
    "axiscbarfontsize = 15\n",
    "\n",
    "# Scatter plot only parameters\n",
    "sc = 8\n",
    "alpha = 0.7\n",
    "\n",
    "# Set axtick dimensions\n",
    "major_size = 6\n",
    "major_width = 1.2\n",
    "minor_size = 3\n",
    "minor_width = 1\n",
    "mpl.rcParams['xtick.major.size'] = major_size\n",
    "mpl.rcParams['xtick.major.width'] = major_width\n",
    "mpl.rcParams['xtick.minor.size'] = minor_size\n",
    "mpl.rcParams['xtick.minor.width'] = minor_width\n",
    "mpl.rcParams['ytick.major.size'] = major_size\n",
    "mpl.rcParams['ytick.major.width'] = major_width\n",
    "mpl.rcParams['ytick.minor.size'] = minor_size\n",
    "mpl.rcParams['ytick.minor.width'] = minor_width\n",
    "\n",
    "mpl.rcParams.update({'figure.autolayout': False})\n",
    "\n",
    "# Seaborn style settings\n",
    "sns.set_style({'axes.axisbelow': True,\n",
    "               'axes.edgecolor': '.8',\n",
    "               'axes.facecolor': 'white',\n",
    "               'axes.grid': True,\n",
    "               'axes.labelcolor': '.15',\n",
    "               'axes.spines.bottom': True,\n",
    "               'axes.spines.left': True,\n",
    "               'axes.spines.right': True,\n",
    "               'axes.spines.top': True,\n",
    "               'figure.facecolor': 'white',\n",
    "               'font.family': ['sans-serif'],\n",
    "               'font.sans-serif': ['Arial',\n",
    "                'DejaVu Sans',\n",
    "                'Liberation Sans',\n",
    "                'Bitstream Vera Sans',\n",
    "                'sans-serif'],\n",
    "               'grid.color': '.8',\n",
    "               'grid.linestyle': '--',\n",
    "               'image.cmap': 'rocket',\n",
    "               'lines.solid_capstyle': 'round',\n",
    "               'patch.edgecolor': 'w',\n",
    "               'patch.force_edgecolor': True,\n",
    "               'text.color': '.15',\n",
    "               'xtick.bottom': True,\n",
    "               'xtick.color': '.15',\n",
    "               'xtick.direction': 'in',\n",
    "               'xtick.top': True,\n",
    "               'ytick.color': '.15',\n",
    "               'ytick.direction': 'in',\n",
    "               'ytick.left': True,\n",
    "               'ytick.right': True})\n",
    "\n",
    "# Colorpalettes, colormaps, etc.\n",
    "sns.set_palette(palette='rocket')\n",
    "rocket_cmap = sns.color_palette('rocket', as_cmap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessed files\n",
    "\n",
    "* ...**sub files**, I selected a *smaller area* of the United States every node is part of this area. And because the navigability feature has no meaning in not fully connected networks, we work with the edgelist, nodelist and neighborlist of the **giant component**(GC) of the network.<br><br>\n",
    "\n",
    "* ...**latlon file** contains every node's ID, with the latitude and longitude coordinates of the node with the transformed **x-y coordinates from lat-lon** (point column) So the euclidean distance works. $d = \\sqrt{(\\vec{x}-\\vec{y})^2}$(https://epsg.io/26917)<br><br>\n",
    "* ...**elist** big networks usually stored as edgelists, each row is an **edge of the network**, edge between a source and a target node. Our network is undirected so the direction or the order of source target nodes doesn't matter.<br><br>\n",
    "\n",
    "* ...**neigh** : Created the **neighborlist of the network**, every node has neighbors (at least 1), those are stored in a **list**, the length of this list is the **degree**, and I added the **local clustering coefficient** of each node to the neighborlist.<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I like long variable names. Sorry.\n",
    "df_neigh_list_sub_GC_nodes = pd.read_excel(path_data+'neighbor_list_small_network_GC.xlsx') \n",
    "df_neigh_list_sub_GC_nodes['neighbors'] = df_neigh_list_sub_GC_nodes.neighbors.apply(lambda x: x[1:-1].split(','))\n",
    "df_neigh_list_sub_GC_nodes['neighbors'] = df_neigh_list_sub_GC_nodes.neighbors.apply(lambda x: [int(xx) for xx in x])\n",
    "\n",
    "df_latlon_sub_GC_nodes = pd.read_excel(path_data+'latlon_points_small_network_GC.xlsx')\n",
    "df_latlon_sub_GC_nodes['point'] = df_latlon_sub_GC_nodes['point'].apply(lambda x: eval(x))\n",
    "\n",
    "df_elist_sub_GC = pd.read_excel(path_data+'edgelist_small_network_GC.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./a. Inspect `df_neigh_list_sub_GC_nodes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_neigh_list_sub_GC_nodes.head())\n",
    "display(df_neigh_list_sub_GC_nodes.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./b. Inspect `df_latlon_sub_GC_nodes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_latlon_sub_GC_nodes.head())\n",
    "display(df_latlon_sub_GC_nodes.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1./c. Inspect `df_elist_sub_GC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_elist_sub_GC.head())\n",
    "display(df_elist_sub_GC.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A few networkscience features\n",
    "* size of network's GC\n",
    "* degree distribution\n",
    "* complementary cumulative degree distribution \n",
    "* degree distribution's exponent with powerlaw (https://pypi.org/project/powerlaw/ and https://nbviewer.jupyter.org/gist/anonymous/bb4e1dfafd9e90d5bc3d with examples)\n",
    "* average clustering coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nr_of_nodes_from_elist(df_elist):\n",
    "    \"\"\"\n",
    "    Returns the number of nodes\n",
    "    \"\"\"\n",
    "    return (df_elist['source'].append(df_elist['target'])).nunique()\n",
    "\n",
    "def nr_of_edges_from_elist(df_elist):\n",
    "    \"\"\"\n",
    "    Returns the number of edges in an edgelist.\n",
    "    \"\"\"\n",
    "    return len(df_elist)\n",
    "\n",
    "def nr_of_edges_from_elist_parallel(df_elist):\n",
    "    \"\"\"\n",
    "    Every edge is parallel in `df_elist`.\n",
    "    \"\"\"\n",
    "    return len(df_elist)//2\n",
    "\n",
    "def make_neigh_list(df_elist):\n",
    "    neighs_of_source = dict(df_elist.groupby(by='source')['target'].apply(list))\n",
    "    \n",
    "    df_neigh = pd.DataFrame({'source':list(neighs_of_source.keys()),\n",
    "                             'neighbors':list(neighs_of_source.values())})\n",
    "    df_neigh['degree'] = df_neigh['neighbors'].apply(len)\n",
    "    return df_neigh\n",
    "\n",
    "def degdist_from_network(G):\n",
    "    degree_sequence = sorted([d for n, d in G.degree()], reverse=True)  # degree sequence\n",
    "    degreeCount = col.Counter(degree_sequence)\n",
    "    return dict(degreeCount.items())\n",
    "\n",
    "def component_sizedist_from_network(G):\n",
    "    connected_components = [len(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "    conn_count = col.Counter(connected_components)\n",
    "    return dict(conn_count.items())\n",
    "\n",
    "def degdist_from_neigh_list(df_neigh):\n",
    "    degree_sequence = sorted(list(df_neigh['degree']))\n",
    "    degreeCount = col.Counter(degree_sequence)\n",
    "    degreeCount = {k:(v/len(df_neigh)) for k,v in degreeCount.items()}\n",
    "    return dict(degreeCount.items())\n",
    "\n",
    "def cum_degdist_complementer_from_neigh_list(df_neigh):\n",
    "    degdist = degdist_from_neigh_list(df_neigh)\n",
    "    degdist = col.OrderedDict(sorted(degdist.items()))\n",
    "\n",
    "    k_vals = list(degdist.keys())\n",
    "    p_probs = list(degdist.values())\n",
    "\n",
    "    cum_probs = {}\n",
    "    for i, k in enumerate(k_vals):\n",
    "        sub_list = [x for x in p_probs[:i+1]]\n",
    "        cum_probs[k] = 1 - sum(sub_list)\n",
    "\n",
    "    return cum_probs\n",
    "\n",
    "def clustering_coeff_neigh_list(df_neigh,node_name):\n",
    "    \n",
    "    neighbors = df_neigh[df_neigh['source']==node_name]['neighbors'].iloc[0]\n",
    "    k = len(neighbors)\n",
    "    if k == 1:\n",
    "        return 0.0\n",
    "    \n",
    "    links = 0.0\n",
    "    \n",
    "    sub_neighs = [set(x) for x in list(df_neigh[df_neigh.source.isin(neighbors)]['neighbors'])]\n",
    "    neighbors = set(neighbors)\n",
    "    for i in range(len(sub_neighs)):\n",
    "        \n",
    "        links += len(sub_neighs[i].intersection(neighbors))\n",
    "    \n",
    "    return links/(k*(k-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nr. of nodes: ', nr_of_nodes_from_elist(df_elist_sub_GC))\n",
    "print('Nr. of edges: ', nr_of_edges_from_elist(df_elist_sub_GC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degree distribution\n",
    "deg_dist_sub = degdist_from_neigh_list(df_neigh_list_sub_GC_nodes)\n",
    "X = list(deg_dist_sub.keys())\n",
    "y = list(deg_dist_sub.values())\n",
    "\n",
    "# Calculate cumulative degree distribution\n",
    "cum_deg_dist_sub = cum_degdist_complementer_from_neigh_list(df_neigh_list_sub_GC_nodes)\n",
    "X_c = list(cum_deg_dist_sub.keys())[:-1]\n",
    "y_c = list(cum_deg_dist_sub.values())[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit power law on the data\n",
    "deg_dist_sub_squence = list(df_neigh_list_sub_GC_nodes.degree)\n",
    "fit_deg = pw.Fit(deg_dist_sub_squence,discrete=True, xmin=20, xmax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_deg.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exponent of degree distribution: {0:.3f} +/- {1:.3f}'.format(fit_deg.alpha, fit_deg.sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_coef_avg = np.average(df_neigh_list_sub_GC_nodes.clus_coeff)\n",
    "print('Avg. clustering coefficient: {0:.3f}'.format(clust_coef_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot edge degree distribution and cumulative degree distribution\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*12, nrows*8),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "# AXES 1. : DEGREE DIST.\n",
    "ax = axes[0]\n",
    "ax.scatter(X, y, label='Degree dist.',\n",
    "           color=rocket_cmap(0.93), ec='black', lw=0.5,\n",
    "           s=sc**2, alpha=alpha)\n",
    "ax.plot(fit_deg.pdf()[0][:-1], fit_deg.pdf()[1], label='Power law slope',\n",
    "        color=cm.magma(0.75), lw=6, ls='-', alpha=0.7)\n",
    "\n",
    "# AXES 2. : CUMULATIVE DEGREE DIST.\n",
    "ax = axes[1]\n",
    "ax.scatter(X_c, y_c,\n",
    "           color=rocket_cmap(0.93), ec='black', lw=0.5,\n",
    "           s=sc**2, alpha=alpha)\n",
    "\n",
    "titles = [\n",
    "    'Degree distribution',\n",
    "    'Complementer cumulative degree distribution',\n",
    "]\n",
    "ylabels = [\n",
    "    '$p_k$',\n",
    "    '$P(x > k)$'\n",
    "]\n",
    "for i, ax in enumerate(axes.reshape(-1)):\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    ax.set_title(titles[i],\n",
    "                 fontsize=axistitlesize, fontweight='bold', color='w')\n",
    "    ax.set_xlabel('$k$', fontsize=axislabelsize, fontweight='bold', color='w')\n",
    "    ax.set_ylabel(ylabels[i], fontsize=axislabelsize, fontweight='bold', color='w')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=axisticksize, colors='w')\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.legend(loc='upper right', fontsize=axislegendsize)\n",
    "\n",
    "plt.savefig(path_pic + 'degdist_small.png',\n",
    "            dpi=200,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance distribution between every pairs\n",
    "\n",
    "* Let's estimate the distance between a handful of users\n",
    "* Let's calculate the distances between 5000 randomly choosen points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df_neigh_list_sub_GC_nodes)\n",
    "space = (((N**2 - 1)/2) * 8) / (1024**3)\n",
    "print('It\\' difficult to calculate the distance between every node. It would require {0:.3f} Gb memory'.format(space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "N_sample = 12000\n",
    "points_coords = np.array([np.array([x[0],x[1]]) for x in df_latlon_sub_GC_nodes.sample(N_sample).point])\n",
    "distances_betw_points = scipy.spatial.distance.cdist(points_coords, points_coords)\n",
    "\n",
    "distances_betw_points = distances_betw_points[distances_betw_points != 0.0]\n",
    "distances_betw_points = distances_betw_points.flatten() / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "samp_size = 100\n",
    "# Create histogram\n",
    "hist, bins = np.histogram(distances_betw_points, bins=samp_size, density=True)\n",
    "width = 1 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create density plot\n",
    "density = gaussian_kde(distances_betw_points)\n",
    "density.covariance_factor = lambda : 0.25\n",
    "density._compute_covariance()\n",
    "xs = np.linspace(0, int(distances_betw_points.max()) + 1, samp_size)\n",
    "ys = density(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,9),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "sc = 8\n",
    "label = ('Histogram with {} bins\\n'.format(samp_size) +\n",
    "         'for {} sample points'.format(N_sample))\n",
    "axes.scatter(center, hist / hist.sum(), label=label,\n",
    "             color=cm.magma(0.93), ec='black', alpha=0.9, s=sc**2)\n",
    "axes.plot(center, hist / hist.sum(),\n",
    "          color=cm.magma(0.93), lw=1, alpha=0.9)\n",
    "#axes.bar(center, (hist / hist.sum()), width=width, label=label,\n",
    "#         color=cm.magma(0.93), ec='black', alpha=0.9)\n",
    "axes.plot(xs, (ys / hist.sum()), label='Gaussian KDE',\n",
    "          color=rocket_cmap(0.65), lw=5, ls='-', alpha=0.6)\n",
    "\n",
    "axes.set_xlabel('Distance [km]', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('Occurence', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_title('Distance distribution between users', fontsize=axistitlesize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, labelrotation=42, colors='white')\n",
    "\n",
    "axes.legend(loc='upper right', fontsize=axislegendsize)\n",
    "\n",
    "plt.savefig(path_pic + 'distance_dist_of_{0}_points_w_kde.png'.format(N_sample),\n",
    "            dpi = 200,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "* The sample is too big to run it myself, and the randomly choosen set doesn't follow a powerlaw.\n",
    "* It's already a subset of the subset of the data. I don't expect similar results. The algorithms are similar to the original research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Greedy algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(t1, t2):\n",
    "    \"\"\"\n",
    "    Returns distance in meters.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(np.array(t1) - np.array(t2))\n",
    "\n",
    "def get_distance_from_node_names(n1,n2,df_latlon):\n",
    "    t1 = df_latlon[df_latlon.user_id == n1].point.iloc[0]\n",
    "    t2 = df_latlon[df_latlon.user_id == n2].point.iloc[0]\n",
    "    return get_distance(t1,t2)\n",
    "\n",
    "def get_closest_neigh_to_target_node(neighbors,target_node,df_latlon):\n",
    "    target_coord = df_latlon[df_latlon.user_id == target_node].point.iloc[0]\n",
    "    \n",
    "    coordinates = [df_latlon[df_latlon.user_id == n].point.iloc[0] for n in neighbors]\n",
    "    distances = [get_distance(t,target_coord) for t in coordinates]\n",
    "    return neighbors[distances.index(min(distances))]\n",
    "\n",
    "def get_closest_neigh_to_target_node_no_reps(neighbors,target_node,df_latlon,path_nodes):\n",
    "    target_coord = df_latlon[df_latlon.user_id == target_node].point.iloc[0]\n",
    "    \n",
    "    coordinates = [df_latlon[df_latlon.user_id == n].point.iloc[0] for n in neighbors]\n",
    "    distances = [get_distance(t,target_coord) for t in coordinates]\n",
    "    distances = [x for x in distances if x not in path_nodes]\n",
    "    \n",
    "    return neighbors[distances.index(min(distances))]\n",
    "\n",
    "def get_greedy_path_with_dist(start_node, target_node, df_neigh, df_latlon,\n",
    "                              max_steps=30, dist_threshold=1000):\n",
    "    \n",
    "    # Distance threshold [meters]\n",
    "    D_THRES = dist_threshold if dist_threshold is not None else np.finfo(np.float64).max\n",
    "    \n",
    "    # If the start node and the end node are the same there's\n",
    "    # nothing to do, return with an empty path list\n",
    "    if start_node == target_node: return []\n",
    "    \n",
    "    # List of nodes visited during the pathing between\n",
    "    # node A (start node) and node B (target node)\n",
    "    path_of_nodes = []\n",
    "    \n",
    "    # Initial 0th state of the Greedy algorithm\n",
    "    nr_step = 0\n",
    "    current_node = start_node\n",
    "    path_of_nodes.append(start_node)\n",
    "    \n",
    "    # Stepping with the Greedy algorithm\n",
    "    while nr_step < max_steps and current_node != target_node:\n",
    "        nr_step +=1 \n",
    "        \n",
    "        # Get the list of the nearest neighbors\n",
    "        neighbors_of_curr = df_neigh[df_neigh.source == current_node].neighbors.iloc[0]\n",
    "        # Exclude the already visited nodes from the selected nearest neighbours\n",
    "        # to prevent infinite loops\n",
    "        neighbors_of_curr = list(set(neighbors_of_curr) - (set(path_of_nodes)))\n",
    "        \n",
    "        # If there are no nodes left, stop and return\n",
    "        # with the so far accumulated node list\n",
    "        if neighbors_of_curr == []: return path_of_nodes\n",
    "        \n",
    "        # Select the nearest node and step on that\n",
    "        current_node = get_closest_neigh_to_target_node(neighbors_of_curr, target_node, df_latlon)\n",
    "        # Add this new node to the path list\n",
    "        path_of_nodes.append(current_node)\n",
    "        \n",
    "        # Break loop, if we are close to the target (distance < D_THRES)\n",
    "        dist_start_curr = get_distance_from_node_names(start_node, current_node, df_latlon)\n",
    "        if dist_start_curr < D_THRES:\n",
    "            nr_step = max_steps\n",
    "    \n",
    "    return path_of_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_pairs = 2000\n",
    "max_hop = 50\n",
    "selected_nodes = np.random.choice(df_neigh_list_sub_GC_nodes.source.values, 2*nr_pairs)\n",
    "starting_points = selected_nodes[:nr_pairs]\n",
    "target_points = selected_nodes[nr_pairs:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_between_points(THRES=1000):\n",
    "    \"\"\"\n",
    "    Collects the path list between all start and end nodes within a given\n",
    "    distance threshold.\n",
    "    \"\"\"    \n",
    "    paths_betw_points_with_dist = []\n",
    "    for i in trange(nr_pairs):\n",
    "        paths_betw_points_with_dist.append(get_greedy_path_with_dist(starting_points[i],\n",
    "                                                                     target_points[i],\n",
    "                                                                     df_neigh_list_sub_GC_nodes,\n",
    "                                                                     df_latlon_sub_GC_nodes,\n",
    "                                                                     max_steps=max_hop,\n",
    "                                                                     dist_threshold=THRES))\n",
    "    return paths_betw_points_with_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_path_data(starting_points, target_points, paths_betw_points_with_dist,\n",
    "                   THRES=1000, nr_pairs=2000):\n",
    "    \n",
    "    df_greedy_results_dist = pd.DataFrame({'start':starting_points,\n",
    "                                           'target':target_points,\n",
    "                                           'path':paths_betw_points_with_dist})\n",
    "    df_greedy_results_dist['path_length'] = \\\n",
    "                    df_greedy_results_dist.path.apply(lambda x: len(x))\n",
    "\n",
    "    # Convert both to [km] by multiplying with 1/1000\n",
    "    df_greedy_results_dist['distance_at_end'] = 1/1000 *\\\n",
    "                    df_greedy_results_dist.apply(lambda x: get_distance_from_node_names(x.target,\n",
    "                                                                                        x.path[-1],\n",
    "                                                                                        df_latlon_sub_GC_nodes), axis=1)\n",
    "    df_greedy_results_dist['distance_at_start'] = 1/1000 *\\\n",
    "                    df_greedy_results_dist.apply(lambda x: get_distance_from_node_names(x.target,\n",
    "                                                                                        x.start,\n",
    "                                                                                        df_latlon_sub_GC_nodes), axis=1)\n",
    "    \n",
    "    df_greedy_results_dist.to_excel(path_data +\n",
    "                                    'greedy_results_distance_threshold_{0}m_{1}_pairs.xlsx'.format(THRES, nr_pairs),\n",
    "                                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./a. : 0.1 km threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Depends on rig, but takes ~10 minutes\n",
    "# with 0.1 km distance threshold\n",
    "# THRES : float in [meters]\n",
    "THRES = 100\n",
    "paths_betw_points_with_dist = paths_between_points(THRES=THRES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_data(starting_points, target_points, paths_betw_points_with_dist,\n",
    "               THRES=THRES, nr_pairs=nr_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./b. : 1 km threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Depends on rig, but takes ~10 minutes\n",
    "# with 1 km distance threshold\n",
    "# THRES : float in [meters]\n",
    "THRES = 1000\n",
    "paths_betw_points_with_dist = paths_between_points(THRES=THRES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_data(starting_points, target_points, paths_betw_points_with_dist,\n",
    "               THRES=THRES, nr_pairs=nr_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4./c. : 10 km threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Depends on rig, but takes ~10 minutes\n",
    "# with 10 km distance threshold\n",
    "# THRES : float in [meters]\n",
    "THRES = 10000\n",
    "paths_betw_points_with_dist = paths_between_points(THRES=THRES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_data(starting_points, target_points, paths_betw_points_with_dist,\n",
    "               THRES=THRES, nr_pairs=nr_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "* The ratio of finished path\n",
    "* Visualize one or two path on the map. \n",
    "* Distribution of required hop numbers\n",
    "* Distribution of the distance between the target node and the starting node\n",
    "* Distribution of the distance between the target node and the last path node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_path_data(THRES=1000, nr_pairs=2000):\n",
    "    \n",
    "    fn = path_data + 'greedy_results_distance_threshold_{0}m_{1}_pairs.xlsx'.format(THRES, nr_pairs)\n",
    "    \n",
    "    df = pd.read_excel(fn)\n",
    "    df['path'] = df.path.apply(lambda x: x[1:-1].split(','))\n",
    "    df['path'] = df.path.apply(lambda x: [int(xx) for xx in x])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greedy_results_dist_100 = load_path_data(THRES=100, nr_pairs=2000)\n",
    "df_greedy_results_dist_1000 = load_path_data(THRES=1000, nr_pairs=2000)\n",
    "df_greedy_results_dist_10000 = load_path_data(THRES=10000, nr_pairs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greedy_results_dist_finished_100 = df_greedy_results_dist_100[df_greedy_results_dist_100.path_length < 51]\n",
    "df_greedy_results_dist_finished_1000 = df_greedy_results_dist_1000[df_greedy_results_dist_1000.path_length < 51]\n",
    "df_greedy_results_dist_finished_10000 = df_greedy_results_dist_10000[df_greedy_results_dist_10000.path_length < 51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_success(df_all,df_finished):\n",
    "    print('The success ratio: {0:.2f}%'.format(len(df_finished)/len(df_all) * 100))\n",
    "    print('{0} successful routing out of {1}\\n'.format(len(df_finished), len(df_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('With 0.1 km threshold:')\n",
    "print_success(df_greedy_results_dist_100,df_greedy_results_dist_finished_100)\n",
    "print('With 1 km threshold:')\n",
    "print_success(df_greedy_results_dist_1000,df_greedy_results_dist_finished_1000)\n",
    "print('With 10 km threshold:')\n",
    "print_success(df_greedy_results_dist_10000,df_greedy_results_dist_finished_10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of steps (hops) needed to reach the target node for different distance thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate path lengths\n",
    "req_hop_nrs_100 = col.Counter(df_greedy_results_dist_finished_100.path_length)\n",
    "req_hop_nrs_1000 = col.Counter(df_greedy_results_dist_finished_1000.path_length)\n",
    "req_hop_nrs_10000 = col.Counter(df_greedy_results_dist_finished_10000.path_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hop_count(req_hop_nrs, color=cm.magma(0.93),\n",
    "                   THRES=1000, nr_pairs=2000):\n",
    "    \n",
    "    # Plot barplot of hop counts\n",
    "    fig, axes = plt.subplots(figsize=(16,9),\n",
    "                             facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "\n",
    "    x = np.array(list(req_hop_nrs.keys()))\n",
    "    y = np.array(list(req_hop_nrs.values()))\n",
    "    axes.bar(x, y/y.sum(), width=1.0, label='Distance < {0} km'.format(THRES),\n",
    "             color=color, ec='black', alpha=0.9)\n",
    "    \n",
    "    axes.set_xlabel('Hop number', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "    axes.set_ylabel('Relative frequency', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "    axes.tick_params(axis='both', which='major', labelsize=axisticksize, labelrotation=42, colors='white')\n",
    "\n",
    "    axes.legend(loc='upper right', fontsize=axislegendsize)\n",
    "    \n",
    "    plt.savefig(path_pic + 'success_plot_distance_threshold_{0}m_{1}_pairs.png'.format(THRES, nr_pairs),\n",
    "                dpi = 200,\n",
    "                bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dist. threshold : $0.1$ km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hop_count(req_hop_nrs_100,\n",
    "               color=cm.magma(0.93),\n",
    "               THRES=0.1, nr_pairs=nr_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dist. threshold : $1$ km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hop_count(req_hop_nrs_1000,\n",
    "               color=cm.magma(0.65),\n",
    "               THRES=1, nr_pairs=nr_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dist. threshold : $10$ km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hop_count(req_hop_nrs_10000,\n",
    "               color=rocket_cmap(0.25),\n",
    "               THRES=10, nr_pairs=nr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot barplot of hop counts\n",
    "fig, axes = plt.subplots(figsize=(16,9),\n",
    "                         facecolor='black', subplot_kw={'facecolor' : 'black'})\n",
    "axes.set_yscale('log')\n",
    "axes.set_ylim(1e-3, 1)\n",
    "\n",
    "reqs = [\n",
    "    req_hop_nrs_100,\n",
    "    req_hop_nrs_1000,\n",
    "    req_hop_nrs_10000,\n",
    "]\n",
    "colors = [\n",
    "    cm.magma(0.93),\n",
    "    cm.magma(0.65),\n",
    "    rocket_cmap(0.25)\n",
    "]\n",
    "thresholds = [\n",
    "    0.1,\n",
    "    1,\n",
    "    10\n",
    "]\n",
    "for i, req in enumerate(reqs):\n",
    "    x = np.array(list(req.keys()))\n",
    "    y = np.array(list(req.values()))\n",
    "    axes.bar(x, y/y.sum(), width=1.0, label='Distance < {0} km'.format(thresholds[i]),\n",
    "             color=colors[i], ec='black', alpha=0.6)\n",
    "\n",
    "axes.set_xlabel('Hop number', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.set_ylabel('Relative frequency', fontsize=axislabelsize, fontweight='bold', color='white')\n",
    "axes.tick_params(axis='both', which='major', labelsize=axisticksize, labelrotation=42, colors='white')\n",
    "\n",
    "axes.legend(loc='upper right', fontsize=axislegendsize)\n",
    "\n",
    "plt.savefig(path_pic + 'success_plot_distance_{0}_pairs.png'.format(nr_pairs),\n",
    "            dpi = 200,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_end = list(df_greedy_results_dist.distance_at_end)\n",
    "# sn.distplot(distances_end,bins=20,norm_hist=False)\n",
    "plt.hist(distances_end,bins=35)\n",
    "plt.xlabel('Distance [km]',fontsize = 15)\n",
    "plt.ylabel('Counter',fontsize=15)\n",
    "plt.title('Distance between the target node and the end of path',fontsize = 15)\n",
    "# plt.savefig(path_pic+'distance_at_end_plot_2000_pairs.png',dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_start = list(df_greedy_results_dist.distance_at_start)\n",
    "# sn.distplot(distances_start,bins=20,norm_hist=False)\n",
    "plt.hist(distances_start,bins=35)\n",
    "plt.ylabel('Counter',fontsize=15)\n",
    "plt.xlabel('Distance [km]',fontsize = 15)\n",
    "plt.title('Distance between the target node and the beginning',fontsize = 15)\n",
    "# plt.savefig(path_pic+'distance_at_start_plot_2000_pairs.png',dpi = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and difficulties:\n",
    "* The algorithm can find a path between the starting and target nodes in general. Or at lest reduce the distance between two users.\n",
    "* But it has its own **limits**:\n",
    "\n",
    "\n",
    "* Doesn't reach the target if the path length would be more than the **max hop number**\n",
    "* **Infinity loops**, in these cases the algorithm breaks and returns with the last closest node\n",
    "* Hop in a **dead end**.  If the closest neighbor to the target has only degree, there it has no more edges, so we can't get closer to the target, and we can't return the last node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +1. Without distance threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_pairs = 2000\n",
    "max_hop = 50\n",
    "selected_nodes = np.random.choice(df_neigh_list_sub_GC_nodes.source.values, 2*nr_pairs)\n",
    "starting_points = selected_nodes[:nr_pairs]\n",
    "target_points = selected_nodes[nr_pairs:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Greedy algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Depends on rig, but takes ~10 minutes\n",
    "# with NO distance threshold\n",
    "# THRES : float in [meters]\n",
    "THRES = None\n",
    "paths_betw_points_with_dist = paths_between_points(THRES=THRES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_data(starting_points, target_points, paths_betw_points_with_dist,\n",
    "               THRES='None', nr_pairs=nr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greedy_results_dist_None = load_path_data(THRES='None', nr_pairs=2000)\n",
    "df_greedy_results_dist_finished_None = df_greedy_results_dist_None[df_greedy_results_dist_None.path_length < 51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('With no distance threshold:')\n",
    "print_success(df_greedy_results_dist_None,df_greedy_results_dist_finished_None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate path lengths\n",
    "req_hop_nrs_None = col.Counter(df_greedy_results_dist_finished_None.path_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hop_count(req_hop_nrs_None,\n",
    "               color=cm.magma(0.93),\n",
    "               THRES='None', nr_pairs=nr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
