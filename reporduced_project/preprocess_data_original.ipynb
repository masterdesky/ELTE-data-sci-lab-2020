{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data: \n",
    "* **Don't try to run these cells**. Takes too much memory, or time. :) \n",
    "* Checked for nan values (at the end a few rows)\n",
    "* Even the previous step is difficult, with the **skip last rows** parameter it already takes too much time, (python engine vs C engine)\n",
    "* I checked for duplicated rows, so called multiple edges, parralel edges, selfloops\n",
    "* The whole basic database contains all (I think) parallel edges, so every row is duplicated, but in reverse order. I couldn't check it, only on a small dataset.\n",
    "* Tried the **DASK** package, but it gives the same problems, only later when I try to load the data.\n",
    "* Selected a small (relatively) area of the map around Missouri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import collections as col\n",
    "\n",
    "import random \n",
    "import seaborn as sn\n",
    "\n",
    "# import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../Data/'\n",
    "path_pic = '../Pictures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_latlon = pd.read_csv(path_data+'gabor_usa_latlon.rpt')\n",
    "# # df_latlon.drop(df_latlon.tail(1).index,inplace=True)\n",
    "# df_latlon['user_id'] = df_latlon['user_id'].astype(int)\n",
    "# df_latlon.drop_duplicates(subset=['user_id','lat','lon'],inplace=True) #drop duplicated rows\n",
    "# df_latlon.drop_duplicates(subset=['user_id'],inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# df_elist = pd.read_csv(path_data+'gabor_usa_mutual_follower_network.rpt')\n",
    "# # df_elist.drop(df_elist.tail(1).index,inplace=True)\n",
    "# df_elist = df_elist.astype(int)\n",
    "# df_elist = df_elist.rename(columns = {'user_id1':'source','user_id2':'target'})\n",
    "\n",
    "# # df_elist.drop_duplicates(subset=['source','target'],keep='first',inplace=True)#drop multi edges\n",
    "# # df_elist = df_elist[df_elist.source != df_elist.target] # drop selfloops\n",
    "\n",
    "# # TOO SLOW, not necessary:\n",
    "# #drop parallel edges:\n",
    "# # df_elist = df_elist.astype(str)\n",
    "# # df_elist['check_string'] = df_elist.apply(lambda row: ''.join(sorted([row['source'], row['target']])), axis=1)\n",
    "# # df_elist.drop_duplicates('check_string',inplace=True)\n",
    "# # df_elist.drop(['check_string'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small selection:\n",
    "\n",
    "Select only a small chunk aroun Missouri:\n",
    "* latitude - -longitude\n",
    "* upper left corner: 40 , -95\n",
    "* bottom right corner: 36 , -89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#df_latlon_sub = df_latlon[(df_latlon.lat < 40) & (df_latlon.lat > 36) & (df_latlon.lon > -95) & (df_latlon.lon < - 89) ]\n",
    "#sub_IDs = list(set(list(df_latlon_sub['user_id'])))\n",
    "#df_elist_sub = df_elist[(df_elist.source.isin(sub_IDs)) & (df_elist.target.isin(sub_IDs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_latlon_sub = pd.read_csv(path_data+'usa_latlon_small.csv')\n",
    "# df_latlon_sub['user_id'] = df_latlon_sub['user_id'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# df_elist_sub = pd.read_csv(path_data+'usa_edgelist_small.csv')\n",
    "\n",
    "# df_elist_sub.drop_duplicates(subset=['source','target'],keep='first',inplace=True)#drop multi edges\n",
    "# df_elist_sub = df_elist_sub[df_elist_sub.source != df_elist_sub.target] # drop selfloops\n",
    "# df_elist_sub = df_elist_sub.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop parallel edges:\n",
    "# df_elist_sub = df_elist_sub.astype(str)\n",
    "# df_elist_sub['check_string'] = df_elist_sub.apply(lambda row: ''.join(sorted([row['source'], row['target']])), axis=1)\n",
    "# df_elist_sub.drop_duplicates('check_string',inplace=True)\n",
    "# df_elist_sub.drop(['check_string'],axis=1,inplace=True)\n",
    "# df_elist_sub = df_elist_sub.astype(int)\n",
    "\n",
    "\n",
    "# #generate parallel edges:\n",
    "# columns_titles = ['target','source']\n",
    "# tmp=df_elist_sub.reindex(columns=columns_titles)\n",
    "# df_elist_sub = pd.concat([df_elist_sub,tmp])\n",
    "# del tmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
